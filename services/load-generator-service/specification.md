Техническое задание на разработку сервиса A (генератор HTTP-нагрузки)
0. Контекст платформы
   Тестовая платформа реализована в виде нескольких взаимодействующих сервисов, развернутых в Docker-контейнерах и связанных между собой по сети.
   Основа прототипа - три микросервиса на Java (Spring Boot):
   Сервис A (клиент-генератор нагрузки): имитирует множество клиентов и генерирует HTTP-запросы заданной интенсивности и профиля. Сервис воспроизводит разные типы нагрузочных сценариев (равномерный поток, всплески, аномальное поведение и т.д.) путем настройки частоты и паттерна отправки запросов. Все запросы сервиса A направляются в сервис C (targetUrl), который затем проксирует их в сервис B.
   Сервис B (целевой сервис): защищаемое приложение, к которому направляются запросы. В прототипе он играет роль упрощенной бизнес-логики (возвращает фиктивный ответ), основная задача - подвергнуться нагрузке и предоставлять метрики производительности (время отклика, процент успешных/ошибочных запросов). Сервис B служит индикатором того, как лимитирование защищает приложение: его стабильность под нагрузкой будет оцениваться.
   Сервис C (балансировщик с механизмом лимитирования): промежуточный прокси между A и B. Он принимает входящие запросы от генератора (A) и решает, пропустить запрос к сервису B или отклонить его, исходя из политики ограничения частоты. Сервис C реализует три алгоритма лимитирования: фиксированное окно, скользящее окно и бакет токенов. Выбор алгоритма и его параметры (например, размер окна или емкость/скорость пополнения бакета) могут переключаться в ходе экспериментов. Для хранения счетчиков запросов и токенов используется внешнее хранилище Redis. Redis развернут в отдельном контейнере; при сбое связи с Redis ограничитель переводится в режим fail-open и перестает блокировать запросы, чтобы не нарушить доступность системы.

   Помимо основных сервисов, в прототип включены инструменты мониторинга и интеллектуальный модуль:
   Система мониторинга (Prometheus): каждый из сервисов A, B, C экспонирует метрики через Spring Boot Actuator (время отклика, количество обработанных и отклоненных запросов, состояние очередей - при наличии и т.д.). Эти данные собираются Prometheus и используются для анализа результатов экспериментов.
   Интеллектуальный компонент: отдельный сервис на Python, прогнозирующий входящий трафик и выдающий рекомендации по настройке параметров лимитирования в режиме реального времени. Модуль использует модель Prophet для анализа истории запросов и выдачи прогнозов. Сервис C периодически запрашивает у интеллектуального модуля обновленные настройки или прогноз; параметры алгоритма могут изменяться "на лету", делая политику ограничения адаптивной.

   Сценарии нагрузки эксперимента:
   Равномерная нормальная нагрузка: сервис A генерирует стабильный поток запросов с постоянной скоростью, не превышающей лимит. Система не должна отклонять запросы без необходимости, время отклика должно оставаться низким.
   Кратковременные всплески трафика: нагрузочный профиль включает пики, превышающие лимит в 2-3 раза, чередуемые с нормальными интервалами. Проверяется, как алгоритмы справляются с краткими перегрузками, и помогает ли интеллектуальный компонент заранее скорректировать лимиты.
   Превышение порога и аномальное поведение: имитация чрезмерной нагрузки (DDoS-подобный сценарий). Ожидается, что лимитирование эффективно отсечет избыточные запросы и защитит сервис B.
   Сбой хранилища или деградация узла: намеренное отключение или замедление Redis/компонентов. При fail-open лимитирование временно отключается, сервис B должен оставаться доступным насколько возможно, а система - восстановиться после возвращения Redis.

   Метрики оценки:
   Среднее время отклика (по ответам сервиса B).
   Процент отклоненных запросов (HTTP 429 Too Many Requests).
   Устойчивость при пиковых нагрузках (отсутствие падений B и скорость восстановления времени отклика).
   Уровень защиты от перегрузок (качественная оценка по совокупности метрик и логов).
1. Общий обзор и назначение
   Сервис A представляет собой клиент-генератор нагрузки, разработанный на Java с использованием фреймворка Spring Boot. Он предназначен для имитации различных профилей HTTP-трафика к целевому веб-сервису с целью исследования влияния алгоритмов ограничения запросов на устойчивость и защищённость распределённых систем (в контексте дипломного проекта). Сервис будет использоваться для нагрузки на систему под тестом, генерируя HTTP-запросы согласно заданному шаблону (профилю) нагрузки.
   Развёртывание: Сервис должен запускаться в Docker-контейнере для удобства развёртывания и изоляции окружения. Это означает, что итоговое приложение Spring Boot будет упаковано в Docker-образ вместе со всеми зависимостями, позволяя запускать сервис на любой платформе, поддерживающей Docker. По‑запросное планирование (как IntervalScheduler) для постоянного/синусоидального/всплесков — равномерность выше, микроберстов нет.
   Основные возможности:
   Гибкая конфигурация теста: Параметры нагрузки задаются во внешнем JSON-файле конфигурации. Этот файл определяет тип профиля нагрузки (паттерн генерации запросов), целевой URL для нагрузки, длительность теста и другие настройки генерации трафика.


Различные профили нагрузки: Сервис поддерживает несколько типов трафик-паттернов (профилей нагрузки) для эмуляции разных сценариев:


Равномерная нагрузка (constant RPS): постоянная интенсивность запросов (запросы генерируются с постоянной частотой).


Всплески (burst): периодические пики нагрузки на фоне более низкого базового уровня (имитация всплесков трафика, например, флэшмобы или разовые акции).


Синусоидальная нагрузка: частота запросов плавно колеблется по синусоидальному закону (медленные периодические подъемы и спады интенсивности, что отражает суточные циклы или аналогичные паттерны трафика).


Пуассоновский поток (Poisson process): случайный поток запросов, имитирующий поведение большого количества независимых пользователей; интервалы между запросами распределены экспоненциально при заданной средней интенсивности (λ).


DDoS-подобная нагрузка: интенсивные, хаотичные всплески трафика, чередующиеся с относительно тихими периодами. Имитация атак типа "отказ в обслуживании", когда на целевой сервер обрушивается большое количество запросов в случайные моменты времени. Такой профиль включает непредсказуемые короткие «удары» высокой нагрузки с нерегулярными интервалами (hit-and-run стратегия).


Управление тестом: Предусмотрен интерфейс запуска и остановки нагрузки. Это может быть реализовано через REST API.
Метрики производительности: Во время генерации нагрузки сервис собирает и экспонирует ключевые метрики через Endpoint Prometheus (HTTP). В частности, доступны метрики времени отклика целей, количества успешно выполненных запросов и ошибок, а также текущей фактической интенсивности запросов (RPS) в реальном времени. Метрики публикуются в формате, совместимом с Prometheus, например через стандартный endpoint /actuator/prometheus Spring Boot.


Логирование: Сервис ведёт журнал событий и результатов в консоль (stdout). По возможности должна быть реализована опция логирования в файл (ротация логов может быть настроена средствами Docker или Linux). Логи позволят отслеживать процесс генерации нагрузки, в том числе запуск/остановку тестов, параметры текущего теста, суммарные показатели и возможные ошибки.


Масштабируемость: Решение должно быть спроектировано так, чтобы можно было запустить несколько экземпляров клиента генератора параллельно (горизонтально масштабировать генерацию нагрузки). Например, для имитации очень высокой нагрузки или распределённой атаки могут одновременно работать несколько контейнеров с сервисом A, каждый с собственной конфигурацией или нацеленный на разные узлы системы. Сервис A не хранит состояния между запросами (stateless), поэтому масштабирование достигается простым увеличением числа запущенных экземпляров.


Отсутствие бизнес-логики: Сервис не выполняет бизнес-операций и не обрабатывает сложные ответы – его единственная задача заключается в генерации HTTP-трафика с заданной частотой и шаблоном. Он должен быть максимально лёгким и производительным, чтобы сам не становился узким местом: по сути это нагрузочный клиент. Все получаемые ответы можно игнорировать или лишь учитывать для метрик (коды ответов и время задержки).


2. Формат конфигурационного JSON-файла
   Для запуска теста сервис принимает на вход JSON-файл с параметрами. Ниже описаны ключевые поля этого файла и их назначение. Все параметры можно задать через JSON; при запуске через REST API содержимое JSON может передаваться в теле запроса.
   Основные поля конфигурации теста:
   targetUrl (строка): URL сервиса C (балансировщик/лимитер), на который отправляются HTTP-запросы генератором нагрузки. URL включает протокол, хост и путь (например: "http://service-c:8082/api/test"). Поддерживаются HTTP и HTTPS адреса. Метод запроса фиксирован - GET.


duration (число): длительность теста нагрузки в секундах. По истечении этого времени сервис автоматически прекратит посылать запросы. Например, 60 означает 60 секунд.


profile (объект): настройки профиля нагрузки. Этот объект определяет тип профиля и связанные параметры. Внутри него должны быть следующие поля:


type (строка): тип профиля нагрузки, один из поддерживаемых – "constant", "burst", "sinusoidal", "poisson", "ddos" (соответствуют перечисленным выше типам нагрузочных паттернов).


params (объект): вложенные параметры, зависящие от выбранного типа профиля. Ниже описано, какие параметры ожидаются для каждого типа:


Если type = "constant": профиль постоянной равномерной нагрузки. Параметры:


rps (число) – целевое постоянное количество запросов в секунду. Сервис будет стремиться равномерно выполнять примерно rps запросов каждую секунду на протяжении всего теста (идеально распределяя их по времени). Например, при rps: 50 – ~50 запросов каждую секунду (интервал между запросами около 20 мс постоянно). Такой профиль полезен для проверки системы в состоянии устойчивой нагрузки.


Если type = "burst": профиль периодических всплесков. Параметры:


baseRps (число) – базовая скорость запросов в секунду в фоновом режиме (между всплесками). Это уровень нагрузки в спокойные периоды.


spikeRps (число) – пиковая скорость во время всплеска нагрузки (количество запросов в секунду на пике).


spikeDuration (число) – длительность одного всплеска в секундах.


spikePeriod (число) – период всплесков в секундах (интервал от начала одного всплеска до начала следующего). Например, при spikePeriod: 60 и spikeDuration: 10 всплески происходят каждую минуту и длятся по 10 секунд. В течение всплеска отправляется spikeRps запросов в секунду, а вне всплесков – baseRps запросов/сек. Этот профиль позволяет проверить систему на способность выдерживать регулярные пиковые нагрузки. Пример: baseRps: 100, spikeRps: 500, spikeDuration: 5, spikePeriod: 60 – генератор будет обычно слать 100 RPS, но каждые 60 секунд в течение 5 секунд нагрузка возрастает до 500 RPS, затем возвращается к базе. (Такой паттерн моделирует, например, периодические всплески пользователей, заходящих волнами). Примечание: параметры можно расширить, например, позволить указывать нестабильность периода или амплитуды, но базовая версия предполагает фиксированные равномерные циклы.


Если type = "sinusoidal": профиль плавно изменяющейся (синусоидальной) нагрузки. Параметры:


minRps (число) – минимальная скорость запросов (нижний предел колебания).


maxRps (число) – максимальная скорость запросов (верхний предел колебания).


period (число) – период колебания в секундах (полный цикл синусоиды).


Сервис будет изменять интенсивность нагрузки по синусоидальному закону между minRps и maxRps. Формально, частота запросов как функция времени t может быть описана как:

RPS(t) = (minRps + maxRps) / 2 + (maxRps - minRps) / 2 * sin(2πt / period),

т.е. среднее значение равно средней точке между min и max, а амплитуда – половина разницы. Например, при minRps=50, maxRps=150, period=120 сгенерируется колеблющаяся нагрузка от 50 до 150 RPS с циклом 2 минуты. Такой профиль имитирует суточные или периодические колебания трафика (ночной спад и дневной пик и т.п.), часто наблюдаемые в реальных системах.


Если type = "poisson": профиль пуассоновского трафика (случайные независимые запросы). Параметры:


averageRps (число) – средняя интенсивность запросов (λ, в запросах в секунду).


Генератор будет слать запросы с случайными интервалами, распределёнными экспоненциально так, чтобы в среднем за секунду получалось averageRps запросов. Данный профиль опирается на пуассоновский процесс: времена между запросами генерируются по экспоненциальному закону с параметром λ = averageRps. На практике это означает, что в некоторые секунды может быть больше запросов, в другие меньше, но в среднем за длительный период интенсивность стремится к λ. Такой режим близко моделирует поведение большого числа независимых пользователей, каждый из которых делает запросы случайным образом, – в результате совокупный поток имеет статистические свойства пуассоновского. Например, averageRps: 20 – в среднем 20 запросов в секунду, но их распределение по времени нерегулярно (возможны кластеры запросов и паузы).


Если type = "ddos": профиль DDoS-подобной нагрузки (интенсивные хаотичные атаки). Параметры:


minRps (число) – фоновые запросы в период относительного затишья (может быть 0 или небольшой уровень фонового трафика).


maxRps (число) – максимальная интенсивность запросов во время атаки (пиковый уровень).


maxSpikeDuration (число) – максимальная длительность атакующего всплеска, секунд.


minIdleTime (число) – минимальный промежуток спокойного времени между атаками, секунд.


maxIdleTime (число) – максимальный промежуток спокойного времени между атаками, секунд.


Данный профиль генерирует непредсказуемые всплески нагрузки: периоды очень высокой интенсивности (до maxRps RPS) длящиеся короткое время (случайно до maxSpikeDuration), чередуются со случайными интервалами затишья (длительностью между minIdleTime и maxIdleTime, в которые нагрузка либо отсутствует, либо равна minRps). Идея – смоделировать поведение распределённой атаки, когда злоумышленники посылают трафик порциями, стараясь сбить защиту. В частности, можно смоделировать burst-атаки (так называемые "hit-and-run"): серия коротких ударов по несколько секунд с огромным трафиком, разделённых минутами или часами простоя. Пример: minRps: 0, maxRps: 1000, maxSpikeDuration: 10, minIdleTime: 20, maxIdleTime: 60 – атаки длятся от нескольких до 10 секунд с интенсивностью до 1000 RPS, потом пауза 20–60 секунд, затем снова атака и т.д.


Примечание: Поля profile.type и соответствующие params обязательны. Если указаны лишние параметры, несоответствующие выбранному профилю, они могут игнорироваться (или вызывать ошибку конфигурации, в зависимости от реализации). В будущем можно рассмотреть поддержку комбинированных или более сложных профилей, но базовая версия ограничивается одним типом за тест.
Другие возможные поля (опционально, для расширения конфигурации):
requestsPerThread / concurrency: число параллельных потоков или асинхронных запросов, которые генератор будет использовать. В базовой реализации это поле можно опустить – сервис сам определит оптимальное число потоков/асинхроных задач исходя из требуемого RPS. Однако, при желании, можно указать явно, например, concurrency: 10 для использования 10 параллельных рабочих потоков.


requestOptions: объект с настройками HTTP-запроса (если потребуется настраивать заголовки, параметры запроса, аутентификацию и пр. – см. раздел Возможные расширения). В базовой версии метод фиксирован GET, тело запроса не используется.


3. Интерфейс запуска и управления тестом
   Сервис предоставляет возможность управлять генерацией нагрузки через REST API. Оба способа являются альтернативными; выбор зависит от сценария использования. Ниже описана структура обоих вариантов:
   3.1 REST API
   При развёртывании сервиса как постоянно работающего микросервиса, удобно организовать REST API для управления. Предлагается реализовать следующие эндпоинты (URI и типы запросов могут быть скорректированы при реализации):
   POST /test/start – запуск теста нагрузки.


Входные данные: тело запроса – JSON с конфигурацией теста (в том же формате, как описано выше, либо путь/имя заранее загруженного конфигурационного профиля).


Действие: Сервис читает параметры, инициализирует генератор нагрузки согласно профилю, и начинает отправлять запросы.


Выходные данные: возвращает подтверждение запуска, например JSON с {"status":"started", "testId": "<идентификатор>"}, где testId – уникальный ID запущенного теста. Если уже запущен другой тест, можно вернуть ошибку (409 Conflict) или опционально остановить предыдущий и запустить новый (но одновременное выполнение двух тестов в одном экземпляре, как правило, не предполагается).


POST /test/stop – остановка текущего теста.


Входные данные: можно не передавать ничего (либо идентификатор теста, если возможно несколько, но базовая реализация – один тест).


Действие: Сервис останавливает генерацию нагрузки заранее, до истечения запланированной длительности. Все рабочие потоки/таски прекращают отправлять запросы по целевому URL.


Выходные данные: подтверждение остановки {"status":"stopped", "testId":"..."}. Если никакой тест не выполнялся – возвращается ошибка (404 Not Found или 400 Bad Request).


GET /test/status – получение статуса текущего теста.


Выходные данные: JSON с информацией о том, выполняется ли сейчас нагрузочный тест, и если да, то его параметры и прогресс. Например:

{
"running": true,
"testId": "12345",
"profile": "burst",
"elapsedTime": 34,
"duration": 60,
"requestsSent": 3400,
"errors": 0
}
Если тест не запущен: {"running": false}. Также статус можно расширить, включая текущую среднюю RPS, последние замеры и т.п.


(Опционально) GET /test/config – отдавать текущую конфигурацию, если тест идёт.


(Опционально) GET /test/history – если нужна история выполненных тестов (в базовом варианте не обязательно, можно ограничиться логами).


Замечания по REST:
Формат и коды ответов должны быть задокументированы. Например, если передан некорректный JSON – возвращать 400 с сообщением об ошибке парсинга; если попытка запуска при уже запущенном тесте – 409 Conflict, и т.д.


Реализация: можно использовать Spring Web (Spring MVC или WebFlux) контроллеры для этих эндпоинтов. Запуск теста будет, вероятно, выполняться асинхронно (не блокировать сам HTTP запрос управления). Т.е. POST /start быстро вернёт ответ, а генерация нагрузки пойдёт в фоновых потоках.
4. Экспортируемые метрики (интеграция с Prometheus)
   Для мониторинга работы генератора и измерения производительности целевого сервиса, сервис A экспонирует ряд метрик в формате Prometheus. Метрики доступны по HTTP endpoint-у (например, GET /actuator/prometheus при включённом Spring Boot Actuator с зависимостью micrometer-prometheus). Эти метрики можно скрапить Prometheus-сервером с заданным интервалом, а затем визуализировать (например, Grafana) или использовать для оценки эффективности алгоритмов rate limiting.
   Основные метрики:
   loadgen_requests_total – счётчик (Counter), общее количество HTTP-запросов, отправленных генератором с момента старта теста. Имеет метки (labels):


status: статус результата запросов, например "success" для 2xx ответов, "rate_limited" для 429 Too Many Requests и "error" для остальных ошибок (включая 4xx/5xx, кроме 429, и сетевые ошибки). Код 429 означает, что клиент превысил установленный лимит запросов за определенный промежуток времени. Таким образом, из одной метрики можно получить общее число запросов, долю успешных и долю отклоненных лимитером.


(возможно) target: метка с хостом или именем целевого сервиса (полезно, если один генератор может работать по разным целям; в простейшем случае можно опустить).


Назначение: позволяет строить графики RPS (по приросту счётчика в единицу времени), вычислять долю ошибок и долю отклоненных лимитером запросов. Counter в Prometheus мономно возрастает в течение работы приложения и сбрасывается при перезапуске.


loadgen_request_duration_seconds – гистограмма (Histogram) или суммарный таймер (Summary), измеряющий время отклика HTTP-запросов (latency) в секундах. Каждый запрос при получении ответа (или таймаута) фиксирует свою длительность.


Если используется гистограмма, она определяется набором бакетов (например, [0.01, 0.05, 0.1, 0.2, 0.5, 1, 2, 5] секунд) и экспонирует ряд метрик: суммарное время, количество, и разбивку по бакетам (стандартный формат Prometheus для Histogram).


Если используется Summary, то экспонируются фрагментиль (квантили) времени ответа. Но предпочтительно Histogram, так как с ней легче вычислять агрегированные показатели по всем генераторам.


Назначение: позволяет наблюдать распределение задержек на сервере под нагрузкой – например, среднее время ответа, percentiles (p90, p99) и т.д., что важно для анализа производительности системы под разными профилями нагрузки.


loadgen_current_rps – гейдж (Gauge), показывающий текущую скорость генерации запросов (в запросах в секунду) в данный момент. Этот показатель можно обновлять либо каждую секунду (например, вычисляя сколько запросов было за последнюю секунду), либо получать непосредственно из внутреннего планировщика запросов. Gauge будет динамически расти или падать в соответствии с профилем: для постоянной нагрузки он стабилен около заданного значения, для синусоидальной – колеблется, для всплесков – покажет пики во время всплесков.


Примечание: хотя RPS можно рассчитать в Prometheus на основе производной от requests_total, прямой gauge удобен для мгновенного отслеживания.


loadgen_errors_total – (опционально) отдельный Counter для количества ошибок (альтернатива метке status в requests_total). Это может быть удобно, если хочется напрямую график ошибок. Однако дублировать не обязательно – либо метка, либо отдельный счётчик.


loadgen_active_threads – (опционально) Gauge, показывающий число потоков/корутин, в данный момент выполняющих запросы. Полезно, если генерация реализована многопоточно, чтобы видеть, сколько параллельных запросов происходит.


loadgen_test_running – Gauge (или флаг) со значением 1, когда тест запущен, и 0, когда нет (чтобы Prometheus мог зафиксировать момент старта/окончания теста; хотя можно определять по изменениям в других метриках).


Системные метрики Java – Поскольку используется Spring Boot Actuator Micrometer, по умолчанию доступны множество JVM и системных метрик (память, CPU, потоки и т.п. – они тоже будут видны на /actuator/prometheus). Они не специфичны для сервиса A, но могут быть полезны, например, чтобы убедиться, что сам генератор не перегружен (например, смотреть его потребление CPU или паузы GC).


Например, jvm_memory_used_bytes, process_cpu_usage, jvm_threads_live и т.д., а также http.server.requests (статистика по самим эндпоинтам REST управления сервисом, хотя они редки). В контексте диплома основное внимание на пользовательские метрики выше, но упомянуть эти дефолтные стоит.


Экспонирование метрик: С сервисом будет интегрирован Prometheus-клиент (например, Micrometer с PrometheusRegistry). При запуске Spring Boot приложения и включении Actuator’s Prometheus endpoint, все метрики доступны по пути /actuator/prometheus. Необходимо убедиться, что в application.properties включено:
management.endpoints.web.exposure.include=health,prometheus
management.endpoint.prometheus.enabled=true

Таким образом, Prometheus сможет опрашивать контейнер генератора (достаточно добавить в конфиг Prometheus джобу, указывающую на хост и порт сервиса A).
Пример содержимого /actuator/prometheus:
# HELP loadgen_requests_total Total HTTP requests sent by load generator
# TYPE loadgen_requests_total counter
loadgen_requests_total{status="success"} 12345
loadgen_requests_total{status="rate_limited"} 89
loadgen_requests_total{status="error"} 67

# HELP loadgen_request_duration_seconds Histogram of request durations
# TYPE loadgen_request_duration_seconds histogram
loadgen_request_duration_seconds_bucket{le="0.05"} 8000
...
loadgen_request_duration_seconds_bucket{le="+Inf"} 13000
loadgen_request_duration_seconds_sum 120.34
loadgen_request_duration_seconds_count 13000

# HELP loadgen_current_rps Current requests per second rate
# TYPE loadgen_current_rps gauge
loadgen_current_rps 250.0

# HELP loadgen_active_threads Number of active request threads
# TYPE loadgen_active_threads gauge
loadgen_active_threads 12

(И так далее, плюс стандартные метрики JVM.)
Эти данные затем могут быть проанализированы для получения результатов теста: например, максимальная достигнутая RPS, процент ошибок, средний и 95-й перцентиль времени ответа и т.п.
5. Внутренняя архитектура сервиса
   Архитектура сервиса A построена модульно, разделяя функциональные компоненты: конфигурация, генерация нагрузки, профили нагрузки, сбор метрик и т.д. Ниже перечислены основные компоненты и их роль:
   Модуль конфигурации – отвечает за чтение и парсинг входного JSON-файла. При запуске через REST – принимает JSON из тела запроса. Этот модуль валидирует конфигурацию (например, проверяет, что указаны все необходимые поля, значения в допустимых диапазонах). Результатом работы является объект (например, TestConfig), содержащий структуру всех настроек, включая тип профиля и его параметры.


Компонент профиля нагрузки (Profile Logic) – реализует логику конкретного профиля нагрузки. Для каждого типа профиля может быть своя стратегия/класс:


Например, класс ConstantLoadProfile с методом, выдающим интервал между запросами или напрямую управляющим отправкой с фиксированным RPS.


Класс BurstLoadProfile – содержащий таймеры или логические счётчики времени, когда должен начаться следующий всплеск и т.д.


SinusoidalProfile – вычисляет в текущий момент требуемую интенсивность по формуле синуса.


PoissonProfile – использует генератор случайных чисел (экспоненциальное распределение) для определения пауз между запросами.


DdosProfile – генерирует случайные пики: может быть реализован, например, через планирование "атаки" (внезапного увеличения RPS) с помощью случайных таймеров.


Эти классы инкапсулируют алгоритм определения когда и сколько запросов нужно слать в единицу времени. Они могут предоставлять интерфейс, например, метод nextInterval() – сколько ждать до следующего запроса, или метод currentRps(t) – вычислить желаемый RPS в момент времени t.


Планировщик запросов (Scheduler) – сердцевина генератора. Он отвечает за режим отправки HTTP-запросов с нужной скоростью. Возможны два подхода:


На основе интервалов: Планировщик запрашивает у компонента профиля время до следующего запроса (например, nextInterval()). Затем спит/ждет указанное время, после чего запускает новый HTTP-запрос, снова получает следующий интервал и т.д. (В многопоточной реализации может быть пул потоков, каждый из которых занимается циклом "ждать-интервал -> послать запрос").


На основе заданий в секунду: Например, можно каждую секунду планировать определённое число задач-HTTP-запросов согласно требуемому RPS. Для синусоиды/пуаcсона – RPS меняется, но можно пересчитывать каждый секунду.


Планировщик должен быть способен точно соблюсти профиль (насколько возможно в условиях планирования задач в ОС/JVM). В Java можно использовать ScheduledExecutorService, Timer, или для более высокой точности – реактивный подход (Project Reactor, WebFlux, где можно контролировать поток запросов).

Многопоточность и асинхронность: Планировщик также управляет пулом потоков или асинхронными воркерами, чтобы посылать несколько запросов параллельно, особенно при высоком RPS. Например, может быть выделен пул из N потоков, или использовать реактивный WebClient (Netty) для большего параллелизма без взрывного роста потоков.


HTTP-клиент (Request Sender) – модуль, непосредственно выполняющий HTTP-запросы к целевому targetUrl. Он может быть реализован с помощью:


Библиотеки Spring WebClient (реактивный, не блокирующий) – предпочтительно для очень больших нагрузок, чтобы эффективно использовать ресурсы.


Или RestTemplate/HttpClient с пулом соединений – для более простого подхода (но он блокирующий, значит на каждый параллельный запрос нужен поток).


Клиент должен поддерживать базовые вещи: возможно, переиспользование keep-alive соединений, настройку таймаута на запрос (чтобы не зависать слишком долго на одном запросе), опционально поддержку HTTPS (что, впрочем, обычно работает из коробки).


Ограничение скорости: Хотя генерация профиля задаёт частоту, нужно учитывать сетевые условия; в идеале, использовать неблокирующую отправку и не дожидаться завершения предыдущих запросов, иначе высокую RPS не получить. Поэтому, например, WebClient с .flatMap() для параллельных запросов.


Обработка ответа: Содержимое ответа, как правило, не важно – но HTTP-код важно учитывать (для метрик успех/ошибка). Поэтому после выполнения запроса нужно проверить статус: если не в диапазоне 200-299, считать как ошибку; 429 учитывать отдельно как rate limited. Время выполнения запроса = разница между отправкой и получением ответа (или таймаута).


Если запрос не получил ответ (timeout или соединение отклонено), тоже считать как ошибка (возможно, с отдельной меткой причины).


Модуль сбора метрик – отвечает за отслеживание результатов запросов и обновление метрик Prometheus. Это можно сделать несколькими способами:


Использовать Micrometer: например, завести Counter requestsTotal и вызывать .increment() на нём для успеха или ошибки (с метками), Timer для времени ответа (Timer.record(duration)), Gauge для RPS (Micrometer позволяет определять Gauge функцией, или вручную обновлять через Gauge.register).


Либо вручную вести счётчики и отдавать их через кастомный /metrics endpoint. Но раз Spring Boot Actuator включен, проще интегрироваться в него.


Процесс: когда HTTP-клиент получает результат запроса, он сообщает модулю метрик, например вызывая metrics.recordRequest(Duration d, boolean success). Модуль метрик внутри инкрементирует нужные счетчики/гистограммы. Важно: Метрики должны быть потокобезопасны, т.к. многие потоки могут одновременно записывать. Micrometer abstractions обычно потокобезопасны.


Test Manager: можно выделить класс, управляющий состоянием теста – запускает планировщик в отдельном потоке, хранит флаг выполнения, обеспечивает возможность остановки. Например, при старте сохраняется Future или thread, который выполняет нагрузку, и при вызове /stop этот поток прерывается или задаётся флаг завершения.


Контроллер статуса опрашивает этот менеджер: сколько запросов выполнено, сколько времени прошло и т.д. (Такие данные дублируют метрики, но можно и напрямую хранить счётчики в менеджере).


Остановка теста: должна быть аккуратно реализована – например, через volatile boolean флаг running = false + у планировщика проверка этого флага между запросами (или прерывание потоков). После остановки все ресурсы (потоки, соединения) освобождаются.


Логирование (Logging) – кросс-компонентный аспект: все важные события пишутся в лог. Используется стандартный логгер (например, SLF4J + Logback).


На info уровне: запуск теста (с параметрами), завершение теста (с итогами: сколько запросов, ошибок, ср. время ответа и т.п.), остановка по команде, существенные изменения (например, начало всплеска, если нужно).


На error уровне: исключения, сбои при отправке запросов, например невозможность резолва DNS, соединение отказано, и т.д. (впрочем, такие вещи можно учитывать и как часть ошибки запроса).


Логи выводятся в консоль (stdout) – в Docker они будут собираться лог-драйвером Docker. По желанию настраивается также вывод в файл (например, logs/app.log внутри контейнера), но это не строго обязательно, можно опираться на консольные логи.


Формат логов: желательно включать временные метки, уровень, сообщение. Например: [2026-01-10 12:00:00,123 INFO] Started load test (profile=burst, target=http://service-c:8082/api/test, duration=60, baseRps=100, spikeRps=500)...


Docker-окружение: Сервис должен корректно работать в контейнере. Это означает, что никаких привязок к локальной файловой системе (кроме как для конфигов, которые мапятся), порты должны быть настраиваемыми через переменные (например, SERVER_PORT), etc. В Dockerfile потребуется:


От базового образа (например, openjdk:17-jdk-slim) копировать jar,


Определить ENTRYPOINT, который запускает приложение (java -jar ...),


Экспонировать порт (например 8080).



Для поддержки обоих вариантов, можно сделать так: если при запуске контейнера указан env CONFIG_FILE, то сразу запуск теста и выход, иначе – запуск веб-сервера. Но это усложняет. Возможно проще собрать два образа или запускать с разными аргументами. В рамках ТЗ можно описать один способ (REST-сервис), а CLI использовать вне Docker (или в Docker, но как показано выше, одноразово).


Модуль расширяемости (hook-ы): архитектура должна позволять в будущем добавлять новые типы профилей (например, Ramp-up, Random Walk и т.д.), новые опции (аутентификация, прокси) без значительных переделок. Для этого профили лучше сделать интерфейсом/абстрактным классом, а не жёстко зашитыми if-ами. Аналогично с HTTP-клиентом: использовать абстракцию (интерфейс RequestExecutor), чтобы его можно было заменить (например, на другой HTTP-бэкенд).


Диаграмма компонентной архитектуры может выглядеть следующим образом (логическая схема):
Input: JSON Config (через файл или REST) →


Config Parser (создаёт TestConfig объект) →


Profile Factory (по типу профиля из конфигурации создаёт инстанс ProfileStrategy) →


Test Manager (запускает тест: создает Scheduler и HTTP Client, инициирует Worker Threads) →


Scheduler (в цикле генерирует по ProfileStrategy либо напрямую RPS и выдаёт задания HTTP Client'у) →


HTTP Client (отправляет запросы, возвращает результат) →


Metrics (фиксирует результат, считает RPS, ошибки, время) + Logger (пишет события) →


... до остановки по времени или команде.


Prometheus Endpoint (параллельно доступен для опроса, предоставляется Micrometer).


(Изображение, если бы было, показало бы как конфиг идёт в профиль, профиль в планировщик, тот управляет worker-ами, они шлют запросы и отчитываются в метрики.)
6. Масштабируемость и производительность
   Сервис A изначально проектируется так, чтобы его можно было масштабировать и адаптировать под разную нагрузку:
   Горизонтальное масштабирование: Для увеличения общей генерируемой нагрузки можно запускать несколько экземпляров сервиса параллельно (например, на разных узлах или контейнерах). Они могут работать независимо, каждый на свой целевой URL или на один и тот же (если нужно скоординированно повысить RPS). Поскольку состояние теста полностью локально в пределах одного экземпляра и внешний мир видит их как отдельных клиентов, проблем с согласованностью нет. Если необходимо, координация (например, одновременный старт) может осуществляться внешним оркестратором. В итоге суммарная нагрузка складывается. Примечание: метрики Prometheus с разных инстансов будут раздельными, их можно агрегировать с помощью promQL при анализе (например, sum по instance).


Вертикальная масштабируемость: На уровне одного экземпляра сервис должен эффективно использовать доступные ресурсы:


Использование асинхронного I/O или достаточного числа потоков позволяет генерировать тысячи RPS с одной машины. Следует убедиться, что нет блокирующих операций, которые лимиитируют throughput (например, запись логов очень частая – можно делать не чаще чем X в секунду или писать агрегировано).


В Docker контейнере можно настроить лимиты CPU/Memory; сервис должен корректно работать и под ограничениями (вплоть до того, что если не хватает CPU на заданный RPS, реальный RPS будет ниже, но сервис остаётся стабильным).


Тестирование производительности генератора: Так как цель – нагрузить систему, сам генератор должен быть лёгким. Желательно провести профилирование или тесты генерации N запросов/с (к некоему локальному быстрым endpoint) чтобы удостовериться, что он способен достичь нужной интенсивности. Если возникнут узкие места (например, у RestTemplate – блокировка на сокетах, или у WebClient – слишком много контекста), можно тюнинговать (увеличить размеры пулов, оптимизировать JSON parse, отключить лишние Spring Boot компоненты, например, не грузить веб-сервер если не нужен).


Ограничения: Один экземпляр, конечно, не бесконечно масштабируется – например, на 1 vCPU генерировать более 1000-2000 RPS может быть уже проблематично (в зависимости от простоты целевого URL). Поэтому на очень высокие нагрузки (десятки тысяч RPS) точно потребуется несколько экземпляров и/или распределение по машинам.


Масштабируемость управления: Если предполагается одновременный запуск нескольких тестов, архитектура может быть расширена для поддержания списка активных тестов. Однако, по ТЗ параллельно один экземпляр запускает один тест. Для большего – использовать несколько экземпляров (или доработать под мульти-тест, но это сложно).


7. Логирование
   Как упоминалось, сервис ведёт протокол работы в логах. Ключевые аспекты логирования:
   Техническая реализация: Использовать встроенные возможности Spring Boot (логгер Logback по умолчанию) или другую библиотеку, но настроить её через application.properties (например, уровень логирования и шаблон вывода). По умолчанию Spring Boot пишет в консоль. Можно указать logging.file.name=app.log чтобы дублировать лог в файл.


Формат сообщений: Включает отметку времени, уровень, источник (класс) и текст. Например:

2026-01-10 15:45:12.345  INFO 1 --- [main] LoadGeneratorApp : Starting load test {profile=constant, rps=100, duration=60, target=http://service-c:8082/api/test}
2026-01-10 15:45:13.789  WARN 1 --- [pool-1-thread-3] HttpClient : Request failed (Connection refused) - will count as error.
2026-01-10 15:46:12.001  INFO 1 --- [main] LoadGeneratorApp : Test completed: 6000 requests sent, 0 errors, avg latency 50ms, p95 80ms.


Уровни логирования:


INFO – основная информация о ходе теста: старт, параметры, окончание, основные статистики.


DEBUG – более подробная отладочная информация (по умолчанию выключено). Например, можно на debug выводить каждые N секунд промежуточный прогресс, или подробности планирования (но это не стоит делать на большом RPS, чтобы не замедлять).


ERROR – неожиданные ситуации: ошибки парсинга конфига, необработанные исключения в потоках генерации, и т.д.


WARN – предупреждения, например если слишком медленный отклик или пропуски запросов.


Консоль vs файл: В Docker среде обычно достаточно консоли, т.к. сбор логов централизован. Но можно настроить опциональный вывод в файл (например, через volume). Если реализуется – файл должен расти ограниченно (можно настроить rolling policy, например, раз в 10MB новый).


Примеры лог-сообщений:


При запуске: "Starting load test with profile=burst (baseRps=100, spikeRps=500) for 120 seconds targeting http://service-c:8082/api/test..."


При достижении всплеска (если нужно): "Burst peak started at t=30s (target RPS=500)"


При ошибке запроса: "Request error: HTTP 500 Internal Server Error (counting as failure)".


При остановке: "Load test stopped by user after 45s. Sent 4500 requests."


Структурированность: Логировать в JSON-формате для удобства разбора, но текстовый читабельный формат тоже подходит.





Техническое задание: Сервис B (целевой сервис)
Обзор
Сервис B представляет собой целевое (защищаемое) приложение, выполняющее упрощённую бизнес-логику. В контексте прототипа системы нагрузочного тестирования сервис B принимает HTTP-запросы, перенаправленные от балансировщика/лимитатора (сервиса C), и возвращает фиктивный ответ. Основная задача сервиса B – подвергаться нагрузке и предоставлять метрики производительности (например, время отклика, процент успешных и ошибочных запросов). Эти метрики используются для оценки эффективности механизмов ограничения частоты запросов (Rate Limiting) и анализа того, насколько лимитирование защищает работоспособность приложения B под нагрузкой.
Назначение и роль сервиса B
Роль в системе: Сервис B играет роль условного «рабочего» приложения, которое защищается от перегрузок. Он служит индикатором устойчивости системы: по стабильности и производительности сервиса B под различной нагрузкой оценивается эффективность алгоритмов лимитирования в сервисе C.


Бизнес-логика: В прототипе бизнес-логика сервиса B упрощена до минимума – он, например, возвращает заранее сформированный фиктивный ответ (статические данные), имитируя успешную обработку запроса. Таким образом исключается влияние сложной логики, а основной упор делается на способность сервиса обрабатывать входящие запросы.


Нагрузочная роль: Сервис B должен корректно функционировать как под нормальной, так и под повышенной нагрузкой. Предполагается, что при перегрузке (когда частота запросов превышает возможности обработки) внешний лимитирующий сервис C отфильтрует избыточные запросы, защищая сервис B от деградации. Стабильность работы сервиса B в условиях экстремальной нагрузки будет ключевым показателем эффективности такой защиты.


Функциональные требования
Обработка HTTP-запросов: Сервис B должен предоставлять REST API эндпоинт GET /api/test, принимающий запросы от сервиса C. Каждый полученный запрос обрабатывается и завершается формированием ответа:


Ответ содержит фиктивные данные (например, простое сообщение или статичный JSON-объект), подтверждающие успешную обработку. Формат и содержание ответа фиксированы для упрощения (например, всегда возвращается статус 200 OK и тело с текстом "OK").


В случае внутренней ошибки сервис B возвращает соответствующий код (например, 500 Internal Server Error), чтобы метрики фиксировали процент ошибочных запросов.


Отсутствие встроенного лимитирования: Сервис B не должен самостоятельно отклонять или ограничивать входящие запросы по частоте. Все решения о пропуске либо отклонении трафика принимает внешний сервис C. Сервис B пытается обработать любой поступивший к нему запрос, демонстрируя реальную нагрузку на приложение при разных режимах работы лимитирования.


Параллельная обработка: Реализация сервиса B должна поддерживать многопоточную обработку, чтобы выдерживать concurrent-нагрузку. Необходимо настроить пул потоков веб-сервера (Spring Boot/Tomcat) на разумные пределы, обеспечивающие одновременно:


Эффективную обработку нескольких одновременных запросов.


Предотвращение истощения ресурсов системы при экстремальной перегрузке (например, с помощью ограничения максимального числа рабочих потоков и очереди запросов).


Фиктивная нагрузка (опционально): Для реалистичности можно предусмотреть имитацию небольшой задержки или вычислительной работы внутри обработчика запроса (например, Thread.sleep(5) мс или выполнение тривиальной операции). Это эмулирует время обработки бизнес-логики и позволяет получить метрики времени отклика, близкие к реальным.


Логирование: Сервис B ведёт базовое логирование:


Фиксация факта приёма и успешного завершения обработки каждого запроса (с отметкой времени).


Запись ошибок или исключений, произошедших при обработке, с стектрейсом.


Такое логирование необходимо для анализа поведения системы в экстремальных ситуациях (например, чтобы убедиться, что B продолжал обработку и не перезапускался во время пиков нагрузки).


Интеграция с другими компонентами
Получение трафика через сервис C: Сервис B расположен за прокси-слоем лимитирования (сервис C). Клиенты (генератор нагрузки A) не обращаются напрямую к B – все запросы проходят через сервис C, который решает, какие запросы пропустить. Таким образом, сервис B получает только трафик, пропущенный политикой ограничения частоты. В конфигурации системы (Docker Compose или аналогичной) сервис C знает адрес/порт сервиса B и маршрутизирует допустимые запросы на него.


Взаимодействие с Redis (опосредованно): Сервис B напрямую не взаимодействует с хранилищем Redis. Вся работа с Redis (хранение счетчиков запросов, токенов для алгоритма «ведро токенов» и т.д.) реализована в сервисе C. Для сервиса B это прозрачно – он получает либо ограниченный поток запросов (при нормальной работе Redis), либо неограниченный поток (если лимитер перешёл в режим fail-open при сбое Redis).


Связь с интеллектуальным модулем: Сервис B никак не взаимодействует с внешним интеллектуальным модулем прогнозирования. Этот модуль через REST API общается с сервисом C и косвенно влияет на B тем, что изменяет параметры лимитирования (например, повышает или снижает порог запросов в секунду). В итоге до B может доходить разный объем трафика в зависимости от прогнозных корректировок, но сам B остаётся пассивным получателем этих изменений.


Мониторинг (Prometheus): Сервис B экспонирует свои метрики через HTTP-эндпоинт (см. раздел "Метрики и мониторинг"). Система мониторинга Prometheus настроена опрашивать (scrape) этот эндпоинт с заданным интервалом. Таким образом, сервис B интегрирован в общую систему мониторинга, предоставляя данные для анализа в реальном времени (например, в Grafana) и последующего сравнения результатов тестов.


Деплой и окружение: Сервис B развёртывается в отдельном Docker-контейнере. Взаимодействие с другими контейнерами включает:


Открытие порта сервиса B (8081) для доступа сервиса C.


Подключение к общей сети Docker, чтобы сервис C мог обращаться к B по имени хоста контейнера.


Переменные окружения или файлы конфигурации внутри контейнера, позволяющие настраивать параметры (порт, префиксы URL и др.) при запуске.


Метрики и мониторинг
Сервис B должен экспонировать ключевые метрики, которые система мониторинга будет собирать для оценки производительности. Реализация мониторинга опирается на Spring Boot Actuator и библиотеку Micrometer с Prometheus-registry.
Экспорт метрик: В приложении B необходимо включить Spring Boot Actuator с эндпоинтами health и prometheus. Это обычно достигается добавлением зависимостей spring-boot-starter-actuator и micrometer-registry-prometheus, а также настройкой в application.properties (например, management.endpoints.web.exposure.include=health,prometheus). В результате по URL, например http://<host>:8081/actuator/prometheus, сервис B будет выдавать стандартные метрики приложения в формате, пригодном для Prometheus.


Ключевые метрики сервиса B:


Время отклика (latency): распределение или среднее время обработки HTTP-запросов. Actuator/Micrometer автоматически предоставляет метрику, например, http_server_requests_seconds (в разбивке по endpoint/status). Это позволит отслеживать, как изменяется время ответа B при росте нагрузки.


Пропускная способность: количество запросов, обрабатываемых сервисом B, например метрика http_server_requests_seconds_count (общее число обработанных запросов) и ее производная – число запросов в секунду.


Успешные и ошибочные ответы: на основе метрик HTTP можно выделить процент успешных запросов (с кодами 2xx) и процент ошибок (5xx). Например, http_server_requests_seconds_count{status="200"} vs {status="500"} покажут соотношение. Это важно для сценариев перегрузки – идеальный лимитирующий алгоритм должен удерживать ошибки на стороне B близкими к нулю.


Ресурсы системы: при возможности, можно включить метрики JVM (память, загрузка CPU) и метрики пула потоков или очередей запросов. Например, размер активных потоков (если доступен через Actuator thread pool metrics) или длина очереди задач. Это поможет понять, насколько ресурсы сервиса B напрягаются под нагрузкой.


Мониторинг доступности: Actuator предоставляет эндпоинт здоровья /actuator/health. Его следует оставить включённым. Prometheus можно настроить на проверку здоровья, а оркестратор контейнеров – на рестарт при падении. Однако, так как цель тестов – наблюдать деградацию B под нагрузкой, автоматический рестарт при ухудшении лучше отключить, чтобы не скрыть эффектов перегрузки.


Сбор данных Prometheus: Prometheus настроен собирать метрики сервиса B (и других сервисов) с заданным интервалом (например, каждые 5-15 секунд). Убедитесь, что в конфигурации Prometheus (prometheus.yml) добавлен job для сервиса B с правильным адресом и портом. Эти данные будут использоваться для построения графиков и расчёта итоговых метрик эффективности после тестов.


Визуализация: В Grafana или аналогичной системе на основе собранных метрик будут построены дашборды, например: график времени отклика B по сценариям, график числа запросов в секунду, доли ошибок. Это необходимо для наглядной демонстрации результатов экспериментов по каждому алгоритму лимитирования.


Нефункциональные требования
Производительность и задержки: В нормальном режиме (нагрузка ≤ лимита) сервис B должен обеспечивать минимально возможное время отклика (порядка нескольких миллисекунд для фиктивной логики) и высокую пропускную способность, ограниченную лишь заданным лимитом. Рост времени отклика под нагрузкой будет сигнализировать о приближении к пределам пропускной способности. Требование: при сценарии равномерной нагрузки, не превышающей лимит, среднее время ответа B должно оставаться стабильным и низким, без ошибок.


Поведение под перегрузкой: В ситуациях, когда входящая нагрузка превышает лимиты (например, флэшмоб или атака), ожидается, что благодаря сервису C до B дойдёт ограниченный поток запросов. Сервис B должен выдерживать поток на уровне заданного лимита без существенной деградации (возможно некоторое увеличение времени отклика, но без массовых отказов). Если же лимитирование отключено (сценарий отказа), сервис B должен максимально долго оставаться работоспособным под лавиной запросов:


Допустимо увеличение очередей и времени отклика, возможно некоторое количество ошибок 5xx из-за таймаутов или истощения ресурсов, но сервис не должен полностью упасть (крайний случай, которого следует избегать).


После прохождения пика нагрузку и восстановления нормального режима, сервис B должен вернуться к стабильной работе (время отклика снижается до исходных значений, ошибки исчезают).


Масштабируемость и отказоустойчивость: Архитектура сервиса B изначально без состояния (stateless), поэтому при необходимости можно запустить несколько экземпляров и горизонтально масштабировать обработку (балансировщик C должен распределять запросы между ними). Также, реализованная стратегия fail-open (в сервисе C) подразумевает, что лучше временно перегрузить B, чем полностью остановить сервис для клиентов – B должен это учитывать. В случае сбоя внешних компонентов (Redis, C) B продолжает работу автономно, обслуживая всё, что к нему приходит.


Безопасность: Несмотря на тестовый характер приложения, следует придерживаться базовых мер безопасности: актуализировать зависимости (Spring Boot и др.), закрыть доступ к служебным эндпоинтам (Actuator) извне, а также предусмотреть защиту от типичных ошибок (например, обработка некорректных входных данных, чтобы они не вызвали непредвиденных исключений). В контексте прототипа нагрузка генерируется контролируемо, поэтому акцент на безопасность минимальный, но для полноты ТЗ эти аспекты упоминаются.


Удобство наблюдения и анализа: Так как ключевая цель сервиса B – предоставить данные для анализа, необходимо обеспечить, чтобы все важные события и состояния фиксировались либо метриками, либо логами. Например, если сервис B начнёт тормозить и ставить запросы в очередь, хорошо, чтобы это отражалось в метриках (размер очереди или время сервера на обработку). Это облегчает последующую интерпретацию результатов эксперимента.


Этапы реализации (пошаговый план)
Чтобы разработать и подготовить сервис B к тестированию, нужно выполнить следующие шаги:
Инициализация проекта: Создать новый Spring Boot-приложение для сервиса B. Подключить необходимые зависимости:


Spring Web (для создания REST API и обработки HTTP-запросов).


Spring Boot Actuator (для экспонирования метрик и состояния здоровья).


Micrometer Prometheus Registry (для интеграции метрик с Prometheus).


Убедиться, что версия Java и используемых библиотек совместима с остальными сервисами (A и C).


Разработка REST API: Реализовать контроллер(ы) в сервисе B. Например, создать контроллер TargetController с методом, обрабатывающим запрос GET /api/test:


Метод не принимает никаких параметров (или минимально необходимую информацию из запроса).


Внутри метода можно добавить небольшую фиктивную задержку или логирование для имитации обработки.


Метод возвращает ResponseEntity<String> со статусом 200 и телом, содержащим, например, строку "OK" (или другой фиксированный ответ).


POST-методы для API сервиса B в базовой версии не используются.


Обработка исключений: Добавить глобальный обработчик ошибок (@ControllerAdvice) или использовать механизмы Spring Boot для обработки неожиданных ситуаций. Цель: любые неперехваченные исключения в логике сервиса B должны приводить к возвращению клиенту HTTP-кода 5xx, чтобы Prometheus мог зафиксировать ошибочный ответ. Также зафиксировать эти события в логах.


Настройка метрик: Включить все необходимые метрики через Actuator:


В файле настроек приложения (например, application.yml) указать management.endpoints.web.exposure.include: health,prometheus, чтобы эндпоинты метрик и здоровья были доступны по HTTP.


Опционально настроить собрание дополнительных метрик (если требуются специальные показатели). Например, используя @Timed аннотации для конкретных методов или вручную инкрементируя счётчики Micrometer в коде, если нужно отследить какое-то событие. В рамках базового прототипа достаточно встроенных метрик HTTP.


Запустить приложение локально и проверить: переход по http://localhost:8081/actuator/health должен вернуть статус "UP", а по http://localhost:8081/actuator/prometheus – список метрик. Убедиться, что там присутствуют метрики HTTP-запросов (они появятся после хотя бы одного обращения к API B).


Docker-упаковка: Написать Dockerfile для сервиса B. Например:


Использовать официальный образ JDK (например, openjdk:17-jdk-alpine) в качестве базового.


Скопировать собранный .jar файл сервиса B в образ.


Установить точку входа: ENTRYPOINT ["java","-jar","/app/service-b.jar"].


Expose 8081 порт.


Собрать образ командой docker build -t service-b:latest . и протестировать локально: запустить контейнер, проверить через docker logs и curl, что сервис стартовал и отвечает на эндпоинты.


Интеграция в docker-compose: Добавить сервис B в docker-compose файл вместе с остальными:


Объявить сервис B, использующий собранный образ, открыть порт 8081 (можно без публикации наружу, только в сети).


Убедиться, что сервис C (лимитирующий прокси) ссылается на сервис B: например, через переменные окружения или конфигурационный файл для C указать URL сервиса B как backend (например, http://service-b:8081).


Перезапустить всю тестовую платформу (A, C, B, Redis, Prometheus) и убедиться, что все сервисы поднялись и видят друг друга. Сервис C в режиме без ограничения должен проксировать все запросы на B, что проверяется простым вызовом к сервису A (генератору): если A отправляет 1 тестовый запрос, C пропускает его, B получает и отвечает (см. логи B или метрики счётчика запросов увеличились).


Тестирование сценариев нагрузки: После успешной интеграции провести серию нагрузочных испытаний согласно сценариям:


Сценарий 1: Равномерная нормальная нагрузка. Настроить сервис A генерировать стабильный поток запросов с частотой, не превышающей лимит, установленный в C. Например, если лимит 100 запросов/с, генерировать 80–100 запросов/с равномерно. Ожидаемый результат:


Сервис C практически не отклоняет запросы (процент 429 близок к 0).


Сервис B получает весь поток, успешно отвечает на все запросы. Среднее время отклика B остаётся низким и почти постоянным, ошибки 5xx отсутствуют.


Эти метрики фиксируются Prometheus (график времени отклика ровный, throughput равен генерации, B стабилен).


Сценарий 2: Кратковременные всплески трафика. Настроить генератор A так, чтобы чередовались периоды нормальной нагрузки и короткие пики, превышающие лимит в несколько раз. Например: 30 секунд при 100% лимита, затем 10 секунд при 300% от лимита, снова спад. Провести тест для разных алгоритмов лимитирования в C (фиксированное окно, скользящее окно, токен-бакет). Наблюдения/требования:


Сервис C должен сглаживать нагрузку: при фиксированном окне возможен краткий всплеск для B на границе окна; при скользящем окне нагрузка на B выравнивается; токен-бакет позволит B принять чуть больше запросов, пока есть накопленные токены, но тоже ограничит длительность пика.


Сервис B под такими всплесками не падает: время отклика может увеличиваться во время пиков, но после них возвращается к норме. На графиках метрик должны прослеживаться всплески latency, соответствующие допущенному трафику. Процент ошибок на B при грамотном лимитировании остаётся минимальным.


Проверить работу интеллектуального модуля: если он включён, возможно, перед ожидаемым пиком он увеличит лимит (тогда B примет больше запросов, пик сгладится менее строго) или снизит лимит (тогда B будет ещё лучше защищён, приняв совсем мало запросов во время всплеска). Отразить в выводах, как это сказалось на метриках B.


Сценарий 3: Аномальная нагрузка, превышение лимитов (имитация DDoS). Настроить сервис A или нескольких агрессивных клиентов отправлять запросы с частотой намного выше лимита. Цель – проверить, что большинство избыточных запросов отклоняется сервисом C, и сервис B не теряет устойчивость. Ожидания:


Процент отклонённых запросов (HTTP 429) в C будет очень высоким (близким к той доле, на которую нагрузка превышает лимит). Например, при 500% нагрузке и лимите 100%, ~80% запросов должны отсеяться.


Сервис B в это время обрабатывает только разрешённые ~20% запросов. По метрикам B: throughput соответствует лимиту, время отклика может немного возрасти из-за близости к максимальной нагрузке, но существенных ошибок нет. B сохраняет работоспособность, тогда как без лимитирования он бы обязательно перегрузился.


Дополнительно проверяется, не приводит ли интенсивная работа лимитера к деградации самого C (это видно косвенно – если C начинает тормозить, то и поток до B уменьшится не только из-за отброса лишнего, но и из-за просадок). Однако для ТЗ на B достаточно отметить, что B защищён от DDoS-подобной нагрузки за счёт фильтрации C.


Сценарий 4: Сбой хранилища или узла (тест отказоустойчивости). Во время одного из тестов намеренно отключить Redis (эмуляция сбоя общего хранилища лимитеров) или притормозить работу сервиса C. При отключении Redis сервис C должен перейти в режим fail-open и перестать лимитировать запросы. Это экстримальный случай, когда весь входящий поток обрушивается на сервис B:


Требование: сервис B должен, насколько возможно, оставаться доступным. В его логах/метриках ожидается значительный рост времени обработки, возможно возникновение ошибок 5xx (например, если очередь запросов переполнится). Однако система не должна полностью «лечь»: хотя бы часть запросов B продолжает обслуживать.


После восстановления связи с Redis (или перезапуска Redis) сервис C возобновит нормальное ограничение трафика. Сервис B должен быстро восстановиться – время отклика вернётся к норме, ошибки прекратятся. В метриках это будет видно как всплеск показателей во время сбоя, затем возврат к стабильной линии.


Такой сценарий демонстрирует баланс между доступностью и защищённостью: политика fail-open выбрана, чтобы не блокировать все запросы при сбое лимитера. ТЗ для B в этой ситуации – пережить кратковременную перегрузку и вернуться к нормальному режиму, что и будет проверено экспериментально.


Анализ результатов: После выполнения всех тестов собрать ключевые метрики для сервиса B по каждому сценарию и алгоритму лимитирования:


Среднее время отклика B в норме и на пике, скорость восстановления.


Доля отклонённых запросов (429) в системе и какова нагрузка на B при этом.


Наличие/отсутствие отказов сервиса B (падений, перезапусков) и процент ошибок 5xx.


Эти данные будут использованы для вывода заключений о «уровне защиты от перегрузок». Если сервис B во всех случаях оставался стабильным и быстродействующим (за исключением контролируемых увеличений времени отклика), значит, лимитирование работало эффективно. Если же при каком-то алгоритме B страдал (например, фиксированное окно пропускало слишком много burst-трафика и B сильно тормозил), это будет учтено как недостаток данного метода лимитирования.


В итоге реализация сервиса B по данному техническому заданию обеспечит надежную основу для экспериментов с нагрузкой. Сервис B будет предоставлять чёткие измеримые показатели, позволяющие сравнить алгоритмы ограничения трафика и подтвердить необходимость адаптивной настройки параметров лимитирования в режиме реального времени.
