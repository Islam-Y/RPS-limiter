Техническое задание на разработку сервиса A (генератор HTTP-нагрузки)
1. Общий обзор и назначение
   Сервис A представляет собой клиент-генератор нагрузки, разработанный на Java с использованием фреймворка Spring Boot. Он предназначен для имитации различных профилей HTTP-трафика к целевому веб-сервису с целью исследования влияния алгоритмов ограничения запросов на устойчивость и защищённость распределённых систем (в контексте дипломного проекта). Сервис будет использоваться для нагрузки на систему под тестом, генерируя HTTP-запросы согласно заданному шаблону (профилю) нагрузки.
   Развёртывание: Сервис должен запускаться в Docker-контейнере для удобства развёртывания и изоляции окружения. Это означает, что итоговое приложение Spring Boot будет упаковано в Docker-образ вместе со всеми зависимостями, позволяя запускать сервис на любой платформе, поддерживающей Docker. По‑запросное планирование (как IntervalScheduler) для постоянного/синусоидального/всплесков — равномерность выше, микроберстов нет.
   Основные возможности:
   Гибкая конфигурация теста: Параметры нагрузки задаются во внешнем JSON-файле конфигурации. Этот файл определяет тип профиля нагрузки (паттерн генерации запросов), целевой URL для нагрузки, длительность теста и другие настройки генерации трафика.


Различные профили нагрузки: Сервис поддерживает несколько типов трафик-паттернов (профилей нагрузки) для эмуляции разных сценариев:


Равномерная нагрузка (constant RPS): постоянная интенсивность запросов (запросы генерируются с постоянной частотой).


Всплески (burst): периодические пики нагрузки на фоне более низкого базового уровня (имитация всплесков трафика, например, флэшмобы или разовые акции).


Синусоидальная нагрузка: частота запросов плавно колеблется по синусоидальному закону (медленные периодические подъемы и спады интенсивности, что отражает суточные циклы или аналогичные паттерны трафика).


Пуассоновский поток (Poisson process): случайный поток запросов, имитирующий поведение большого количества независимых пользователей; интервалы между запросами распределены экспоненциально при заданной средней интенсивности (λ).


DDoS-подобная нагрузка: интенсивные, хаотичные всплески трафика, чередующиеся с относительно тихими периодами. Имитация атак типа "отказ в обслуживании", когда на целевой сервер обрушивается большое количество запросов в случайные моменты времени. Такой профиль включает непредсказуемые короткие «удары» высокой нагрузки с нерегулярными интервалами (hit-and-run стратегия).


Управление тестом: Предусмотрен интерфейс запуска и остановки нагрузки. Это может быть реализовано через REST API.
Метрики производительности: Во время генерации нагрузки сервис собирает и экспонирует ключевые метрики через Endpoint Prometheus (HTTP). В частности, доступны метрики времени отклика целей, количества успешно выполненных запросов и ошибок, а также текущей фактической интенсивности запросов (RPS) в реальном времени. Метрики публикуются в формате, совместимом с Prometheus, например через стандартный endpoint /actuator/prometheus Spring Boot.


Логирование: Сервис ведёт журнал событий и результатов в консоль (stdout). По возможности должна быть реализована опция логирования в файл (ротация логов может быть настроена средствами Docker или Linux). Логи позволят отслеживать процесс генерации нагрузки, в том числе запуск/остановку тестов, параметры текущего теста, суммарные показатели и возможные ошибки.


Масштабируемость: Решение должно быть спроектировано так, чтобы можно было запустить несколько экземпляров клиента генератора параллельно (горизонтально масштабировать генерацию нагрузки). Например, для имитации очень высокой нагрузки или распределённой атаки могут одновременно работать несколько контейнеров с сервисом A, каждый с собственной конфигурацией или нацеленный на разные узлы системы. Сервис A не хранит состояния между запросами (stateless), поэтому масштабирование достигается простым увеличением числа запущенных экземпляров.


Отсутствие бизнес-логики: Сервис не выполняет бизнес-операций и не обрабатывает сложные ответы – его единственная задача заключается в генерации HTTP-трафика с заданной частотой и шаблоном. Он должен быть максимально лёгким и производительным, чтобы сам не становился узким местом: по сути это нагрузочный клиент. Все получаемые ответы можно игнорировать или лишь учитывать для метрик (коды ответов и время задержки).


2. Формат конфигурационного JSON-файла
   Для запуска теста сервис принимает на вход JSON-файл с параметрами. Ниже описаны ключевые поля этого файла и их назначение. Все параметры можно задать через JSON; при запуске через REST API содержимое JSON может передаваться в теле запроса.
   Основные поля конфигурации теста:
   targetUrl (строка): целевой URL, на который будут отправляться HTTP-запросы генератором нагрузки. Этот URL включает протокол, хост и путь (например: "http://example.com/api/test"). Поддерживаются как HTTP, так и HTTPS адреса. Метод запроса по умолчанию – GET, если не указано иное (опционально можно расширить JSON, чтобы указывать тип HTTP-метода и тело запроса, но в базовой реализации достаточно GET-запросов).


duration (число или строка): длительность теста нагрузки. Определяет, сколько времени (в секундах, либо в формате ISO8601 duration) будет генерироваться трафик после запуска. По истечении этого времени сервис автоматически прекратит посылать запросы. Например, 60 означает 60 секунд. Можно предусмотреть суффиксы времени (например, "5m" для 5 минут) для удобства.


profile (объект): настройки профиля нагрузки. Этот объект определяет тип профиля и связанные параметры. Внутри него должны быть следующие поля:


type (строка): тип профиля нагрузки, один из поддерживаемых – "constant", "burst", "sinusoidal", "poisson", "ddos" (соответствуют перечисленным выше типам нагрузочных паттернов).


params (объект): вложенные параметры, зависящие от выбранного типа профиля. Ниже описано, какие параметры ожидаются для каждого типа:


Если type = "constant": профиль постоянной равномерной нагрузки. Параметры:


rps (число) – целевое постоянное количество запросов в секунду. Сервис будет стремиться равномерно выполнять примерно rps запросов каждую секунду на протяжении всего теста (идеально распределяя их по времени). Например, при rps: 50 – ~50 запросов каждую секунду (интервал между запросами около 20 мс постоянно). Такой профиль полезен для проверки системы в состоянии устойчивой нагрузки.


Если type = "burst": профиль периодических всплесков. Параметры:


baseRps (число) – базовая скорость запросов в секунду в фоновом режиме (между всплесками). Это уровень нагрузки в спокойные периоды.


spikeRps (число) – пиковая скорость во время всплеска нагрузки (количество запросов в секунду на пике).


spikeDuration (число) – длительность одного всплеска в секундах.


spikePeriod (число) – период всплесков в секундах (интервал от начала одного всплеска до начала следующего). Например, при spikePeriod: 60 и spikeDuration: 10 всплески происходят каждую минуту и длятся по 10 секунд. В течение всплеска отправляется spikeRps запросов в секунду, а вне всплесков – baseRps запросов/сек. Этот профиль позволяет проверить систему на способность выдерживать регулярные пиковые нагрузки. Пример: baseRps: 100, spikeRps: 500, spikeDuration: 5, spikePeriod: 60 – генератор будет обычно слать 100 RPS, но каждые 60 секунд в течение 5 секунд нагрузка возрастает до 500 RPS, затем возвращается к базе. (Такой паттерн моделирует, например, периодические всплески пользователей, заходящих волнами). Примечание: параметры можно расширить, например, позволить указывать нестабильность периода или амплитуды, но базовая версия предполагает фиксированные равномерные циклы.


Если type = "sinusoidal": профиль плавно изменяющейся (синусоидальной) нагрузки. Параметры:


minRps (число) – минимальная скорость запросов (нижний предел колебания).


maxRps (число) – максимальная скорость запросов (верхний предел колебания).


period (число) – период колебания в секундах (полный цикл синусоиды).


Сервис будет изменять интенсивность нагрузки по синусоидальному закону между minRps и maxRps. Формально, частота запросов как функция времени t может быть описана как:

RPS(t)=minRps+maxRps2+maxRps−minRps2sin⁡(2πtperiod),RPS(t) = \frac{minRps + maxRps}{2} + \frac{maxRps - minRps}{2} \sin\left(\frac{2\pi t}{period}\right),RPS(t)=2minRps+maxRps​+2maxRps−minRps​sin(period2πt​),

т.е. среднее значение равно средней точке между min и max, а амплитуда – половина разницы. Например, при minRps=50, maxRps=150, period=120 сгенерируется колеблющаяся нагрузка от 50 до 150 RPS с циклом 2 минуты. Такой профиль имитирует суточные или периодические колебания трафика (ночной спад и дневной пик и т.п.), часто наблюдаемые в реальных системах.


Если type = "poisson": профиль пуассоновского трафика (случайные независимые запросы). Параметры:


averageRps (число) – средняя интенсивность запросов (λ, в запросах в секунду).


Генератор будет слать запросы с случайными интервалами, распределёнными экспоненциально так, чтобы в среднем за секунду получалось averageRps запросов. Данный профиль опирается на пуассоновский процесс: времена между запросами генерируются по экспоненциальному закону с параметром λ = averageRps. На практике это означает, что в некоторые секунды может быть больше запросов, в другие меньше, но в среднем за длительный период интенсивность стремится к λ. Такой режим близко моделирует поведение большого числа независимых пользователей, каждый из которых делает запросы случайным образом, – в результате совокупный поток имеет статистические свойства пуассоновского. Например, averageRps: 20 – в среднем 20 запросов в секунду, но их распределение по времени нерегулярно (возможны кластеры запросов и паузы).


Если type = "ddos": профиль DDoS-подобной нагрузки (интенсивные хаотичные атаки). Параметры:


minRps (число) – фоновые запросы в период относительного затишья (может быть 0 или небольшой уровень фонового трафика).


maxRps (число) – максимальная интенсивность запросов во время атаки (пиковый уровень).


maxSpikeDuration (число) – максимальная длительность атакующего всплеска, секунд.


minIdleTime (число) – минимальный промежуток спокойного времени между атаками, секунд.


maxIdleTime (число) – максимальный промежуток спокойного времени между атаками, секунд.


Данный профиль генерирует непредсказуемые всплески нагрузки: периоды очень высокой интенсивности (до maxRps RPS) длящиеся короткое время (случайно до maxSpikeDuration), чередуются со случайными интервалами затишья (длительностью между minIdleTime и maxIdleTime, в которые нагрузка либо отсутствует, либо равна minRps). Идея – смоделировать поведение распределённой атаки, когда злоумышленники посылают трафик порциями, стараясь сбить защиту. В частности, можно смоделировать burst-атаки (так называемые "hit-and-run"): серия коротких ударов по несколько секунд с огромным трафиком, разделённых минутами или часами простоя. Пример: minRps: 0, maxRps: 1000, maxSpikeDuration: 10, minIdleTime: 20, maxIdleTime: 60 – атаки длятся от нескольких до 10 секунд с интенсивностью до 1000 RPS, потом пауза 20–60 секунд, затем снова атака и т.д.


Примечание: Поля profile.type и соответствующие params обязательны. Если указаны лишние параметры, несоответствующие выбранному профилю, они могут игнорироваться (или вызывать ошибку конфигурации, в зависимости от реализации). В будущем можно рассмотреть поддержку комбинированных или более сложных профилей, но базовая версия ограничивается одним типом за тест.
Другие возможные поля (опционально, для расширения конфигурации):
requestsPerThread / concurrency: число параллельных потоков или асинхронных запросов, которые генератор будет использовать. В базовой реализации это поле можно опустить – сервис сам определит оптимальное число потоков/асинхроных задач исходя из требуемого RPS. Однако, при желании, можно указать явно, например, concurrency: 10 для использования 10 параллельных рабочих потоков.


requestOptions: объект с настройками HTTP-запроса (если потребуется настраивать заголовки, метод, тело, аутентификацию и пр. – см. раздел Возможные расширения). В рамках базового ТЗ можно не использовать, предполагая простые GET-запросы без дополнительных заголовков.


3. Интерфейс запуска и управления тестом
   Сервис предоставляет возможность управлять генерацией нагрузки через REST API. Оба способа являются альтернативными; выбор зависит от сценария использования. Ниже описана структура обоих вариантов:
   3.1 REST API
   При развёртывании сервиса как постоянно работающего микросервиса, удобно организовать REST API для управления. Предлагается реализовать следующие эндпоинты (URI и типы запросов могут быть скорректированы при реализации):
   POST /test/start – запуск теста нагрузки.


Входные данные: тело запроса – JSON с конфигурацией теста (в том же формате, как описано выше, либо путь/имя заранее загруженного конфигурационного профиля).


Действие: Сервис читает параметры, инициализирует генератор нагрузки согласно профилю, и начинает отправлять запросы.


Выходные данные: возвращает подтверждение запуска, например JSON с {"status":"started", "testId": "<идентификатор>"}, где testId – уникальный ID запущенного теста. Если уже запущен другой тест, можно вернуть ошибку (409 Conflict) или опционально остановить предыдущий и запустить новый (но одновременное выполнение двух тестов в одном экземпляре, как правило, не предполагается).


POST /test/stop – остановка текущего теста.


Входные данные: можно не передавать ничего (либо идентификатор теста, если возможно несколько, но базовая реализация – один тест).


Действие: Сервис останавливает генерацию нагрузки заранее, до истечения запланированной длительности. Все рабочие потоки/таски прекращают отправлять запросы по целевому URL.


Выходные данные: подтверждение остановки {"status":"stopped", "testId":"..."}. Если никакой тест не выполнялся – возвращается ошибка (404 Not Found или 400 Bad Request).


GET /test/status – получение статуса текущего теста.


Выходные данные: JSON с информацией о том, выполняется ли сейчас нагрузочный тест, и если да, то его параметры и прогресс. Например:

{
"running": true,
"testId": "12345",
"profile": "burst",
"elapsedTime": 34,
"duration": 60,
"requestsSent": 3400,
"errors": 0
}
Если тест не запущен: {"running": false}. Также статус можно расширить, включая текущую среднюю RPS, последние замеры и т.п.


(Опционально) GET /test/config – отдавать текущую конфигурацию, если тест идёт.


(Опционально) GET /test/history – если нужна история выполненных тестов (в базовом варианте не обязательно, можно ограничиться логами).


Замечания по REST:
Формат и коды ответов должны быть задокументированы. Например, если передан некорректный JSON – возвращать 400 с сообщением об ошибке парсинга; если попытка запуска при уже запущенном тесте – 409 Conflict, и т.д.


Реализация: можно использовать Spring Web (Spring MVC или WebFlux) контроллеры для этих эндпоинтов. Запуск теста будет, вероятно, выполняться асинхронно (не блокировать сам HTTP запрос управления). Т.е. POST /start быстро вернёт ответ, а генерация нагрузки пойдёт в фоновых потоках.
4. Экспортируемые метрики (интеграция с Prometheus)
   Для мониторинга работы генератора и измерения производительности целевого сервиса, сервис A экспонирует ряд метрик в формате Prometheus. Метрики доступны по HTTP endpoint-у (например, GET /actuator/prometheus при включённом Spring Boot Actuator с зависимостью micrometer-prometheus). Эти метрики можно скрапить Prometheus-сервером с заданным интервалом, а затем визуализировать (например, Grafana) или использовать для оценки эффективности алгоритмов rate limiting.
   Основные метрики:
   loadgen_requests_total – счётчик (Counter), общее количество HTTP-запросов, отправленных генератором с момента старта теста. Имеет метки (labels):


status: статус результата запросов, например "success" для успешно получивших 2xx ответ, "error" для запросов, завершившихся ошибкой (HTTP 4xx/5xx или сетевой ошибкой). Таким образом, из одной метрики можно получить как всего отправлено запросов, так и сколько из них завершились ошибкой.


(возможно) target: метка с хостом или именем целевого сервиса (полезно, если один генератор может работать по разным целям; в простейшем случае можно опустить).


Назначение: позволяет строить графики RPS (по приросту счётчика в единицу времени) и вычислять долю ошибок. Counter в Prometheus мономно возрастает в течение работы приложения и сбрасывается при перезапуске.


loadgen_request_duration_seconds – гистограмма (Histogram) или суммарный таймер (Summary), измеряющий время отклика HTTP-запросов (latency) в секундах. Каждый запрос при получении ответа (или таймаута) фиксирует свою длительность.


Если используется гистограмма, она определяется набором бакетов (например, [0.01, 0.05, 0.1, 0.2, 0.5, 1, 2, 5] секунд) и экспонирует ряд метрик: суммарное время, количество, и разбивку по бакетам (стандартный формат Prometheus для Histogram).


Если используется Summary, то экспонируются фрагментиль (квантили) времени ответа. Но предпочтительно Histogram, так как с ней легче вычислять агрегированные показатели по всем генераторам.


Назначение: позволяет наблюдать распределение задержек на сервере под нагрузкой – например, среднее время ответа, percentiles (p90, p99) и т.д., что важно для анализа производительности системы под разными профилями нагрузки.


loadgen_current_rps – гейдж (Gauge), показывающий текущую скорость генерации запросов (в запросах в секунду) в данный момент. Этот показатель можно обновлять либо каждую секунду (например, вычисляя сколько запросов было за последнюю секунду), либо получать непосредственно из внутреннего планировщика запросов. Gauge будет динамически расти или падать в соответствии с профилем: для постоянной нагрузки он стабилен около заданного значения, для синусоидальной – колеблется, для всплесков – покажет пики во время всплесков.


Примечание: хотя RPS можно рассчитать в Prometheus на основе производной от requests_total, прямой gauge удобен для мгновенного отслеживания.


loadgen_errors_total – (опционально) отдельный Counter для количества ошибок (альтернатива метке status в requests_total). Это может быть удобно, если хочется напрямую график ошибок. Однако дублировать не обязательно – либо метка, либо отдельный счётчик.


loadgen_active_threads – (опционально) Gauge, показывающий число потоков/корутин, в данный момент выполняющих запросы. Полезно, если генерация реализована многопоточно, чтобы видеть, сколько параллельных запросов происходит.


loadgen_test_running – Gauge (или флаг) со значением 1, когда тест запущен, и 0, когда нет (чтобы Prometheus мог зафиксировать момент старта/окончания теста; хотя можно определять по изменениям в других метриках).


Системные метрики Java – Поскольку используется Spring Boot Actuator Micrometer, по умолчанию доступны множество JVM и системных метрик (память, CPU, потоки и т.п. – они тоже будут видны на /actuator/prometheus). Они не специфичны для сервиса A, но могут быть полезны, например, чтобы убедиться, что сам генератор не перегружен (например, смотреть его потребление CPU или паузы GC).


Например, jvm_memory_used_bytes, process_cpu_usage, jvm_threads_live и т.д., а также http.server.requests (статистика по самим эндпоинтам REST управления сервисом, хотя они редки). В контексте диплома основное внимание на пользовательские метрики выше, но упомянуть эти дефолтные стоит.


Экспонирование метрик: С сервисом будет интегрирован Prometheus-клиент (например, Micrometer с PrometheusRegistry). При запуске Spring Boot приложения и включении Actuator’s Prometheus endpoint, все метрики доступны по пути /actuator/prometheus. Необходимо убедиться, что в application.properties включено:
management.endpoints.web.exposure.include=prometheus
management.endpoint.prometheus.enabled=true

Таким образом, Prometheus сможет опрашивать контейнер генератора (достаточно добавить в конфиг Prometheus джобу, указывающую на хост и порт сервиса A).
Пример содержимого /actuator/prometheus:
# HELP loadgen_requests_total Total HTTP requests sent by load generator
# TYPE loadgen_requests_total counter
loadgen_requests_total{status="success"} 12345
loadgen_requests_total{status="error"} 67

# HELP loadgen_request_duration_seconds Histogram of request durations
# TYPE loadgen_request_duration_seconds histogram
loadgen_request_duration_seconds_bucket{le="0.05"} 8000
...
loadgen_request_duration_seconds_bucket{le="+Inf"} 13000
loadgen_request_duration_seconds_sum 120.34
loadgen_request_duration_seconds_count 13000

# HELP loadgen_current_rps Current requests per second rate
# TYPE loadgen_current_rps gauge
loadgen_current_rps 250.0

# HELP loadgen_active_threads Number of active request threads
# TYPE loadgen_active_threads gauge
loadgen_active_threads 12

(И так далее, плюс стандартные метрики JVM.)
Эти данные затем могут быть проанализированы для получения результатов теста: например, максимальная достигнутая RPS, процент ошибок, средний и 95-й перцентиль времени ответа и т.п.
5. Внутренняя архитектура сервиса
   Архитектура сервиса A построена модульно, разделяя функциональные компоненты: конфигурация, генерация нагрузки, профили нагрузки, сбор метрик и т.д. Ниже перечислены основные компоненты и их роль:
   Модуль конфигурации – отвечает за чтение и парсинг входного JSON-файла. При запуске через REST – принимает JSON из тела запроса. Этот модуль валидирует конфигурацию (например, проверяет, что указаны все необходимые поля, значения в допустимых диапазонах). Результатом работы является объект (например, TestConfig), содержащий структуру всех настроек, включая тип профиля и его параметры.


Компонент профиля нагрузки (Profile Logic) – реализует логику конкретного профиля нагрузки. Для каждого типа профиля может быть своя стратегия/класс:


Например, класс ConstantLoadProfile с методом, выдающим интервал между запросами или напрямую управляющим отправкой с фиксированным RPS.


Класс BurstLoadProfile – содержащий таймеры или логические счётчики времени, когда должен начаться следующий всплеск и т.д.


SinusoidalProfile – вычисляет в текущий момент требуемую интенсивность по формуле синуса.


PoissonProfile – использует генератор случайных чисел (экспоненциальное распределение) для определения пауз между запросами.


DdosProfile – генерирует случайные пики: может быть реализован, например, через планирование "атаки" (внезапного увеличения RPS) с помощью случайных таймеров.


Эти классы инкапсулируют алгоритм определения когда и сколько запросов нужно слать в единицу времени. Они могут предоставлять интерфейс, например, метод nextInterval() – сколько ждать до следующего запроса, или метод currentRps(t) – вычислить желаемый RPS в момент времени t.


Планировщик запросов (Scheduler) – сердцевина генератора. Он отвечает за режим отправки HTTP-запросов с нужной скоростью. Возможны два подхода:


На основе интервалов: Планировщик запрашивает у компонента профиля время до следующего запроса (например, nextInterval()). Затем спит/ждет указанное время, после чего запускает новый HTTP-запрос, снова получает следующий интервал и т.д. (В многопоточной реализации может быть пул потоков, каждый из которых занимается циклом "ждать-интервал -> послать запрос").


На основе заданий в секунду: Например, можно каждую секунду планировать определённое число задач-HTTP-запросов согласно требуемому RPS. Для синусоиды/пуаcсона – RPS меняется, но можно пересчитывать каждый секунду.


Планировщик должен быть способен точно соблюсти профиль (насколько возможно в условиях планирования задач в ОС/JVM). В Java можно использовать ScheduledExecutorService, Timer, или для более высокой точности – реактивный подход (Project Reactor, WebFlux, где можно контролировать поток запросов).

Многопоточность и асинхронность: Планировщик также управляет пулом потоков или асинхронными воркерами, чтобы посылать несколько запросов параллельно, особенно при высоком RPS. Например, может быть выделен пул из N потоков, или использовать реактивный WebClient (Netty) для большего параллелизма без взрывного роста потоков.


HTTP-клиент (Request Sender) – модуль, непосредственно выполняющий HTTP-запросы к целевому targetUrl. Он может быть реализован с помощью:


Библиотеки Spring WebClient (реактивный, не блокирующий) – предпочтительно для очень больших нагрузок, чтобы эффективно использовать ресурсы.


Или RestTemplate/HttpClient с пулом соединений – для более простого подхода (но он блокирующий, значит на каждый параллельный запрос нужен поток).


Клиент должен поддерживать базовые вещи: возможно, переиспользование keep-alive соединений, настройку таймаута на запрос (чтобы не зависать слишком долго на одном запросе), опционально поддержку HTTPS (что, впрочем, обычно работает из коробки).


Ограничение скорости: Хотя генерация профиля задаёт частоту, нужно учитывать сетевые условия; в идеале, использовать неблокирующую отправку и не дожидаться завершения предыдущих запросов, иначе высокую RPS не получить. Поэтому, например, WebClient с .flatMap() для параллельных запросов.


Обработка ответа: Содержимое ответа, как правило, не важно – но HTTP-код важно учитывать (для метрик успех/ошибка). Поэтому после выполнения запроса нужно проверить статус: если не в диапазоне 200-399, считать как ошибку. Время выполнения запроса = разница между отправкой и получением ответа (или таймаута).


Если запрос не получил ответ (timeout или соединение отклонено), тоже считать как ошибка (возможно, с отдельной меткой причины).


Модуль сбора метрик – отвечает за отслеживание результатов запросов и обновление метрик Prometheus. Это можно сделать несколькими способами:


Использовать Micrometer: например, завести Counter requestsTotal и вызывать .increment() на нём для успеха или ошибки (с метками), Timer для времени ответа (Timer.record(duration)), Gauge для RPS (Micrometer позволяет определять Gauge функцией, или вручную обновлять через Gauge.register).


Либо вручную вести счётчики и отдавать их через кастомный /metrics endpoint. Но раз Spring Boot Actuator включен, проще интегрироваться в него.


Процесс: когда HTTP-клиент получает результат запроса, он сообщает модулю метрик, например вызывая metrics.recordRequest(Duration d, boolean success). Модуль метрик внутри инкрементирует нужные счетчики/гистограммы. Важно: Метрики должны быть потокобезопасны, т.к. многие потоки могут одновременно записывать. Micrometer abstractions обычно потокобезопасны.


Test Manager: можно выделить класс, управляющий состоянием теста – запускает планировщик в отдельном потоке, хранит флаг выполнения, обеспечивает возможность остановки. Например, при старте сохраняется Future или thread, который выполняет нагрузку, и при вызове /stop этот поток прерывается или задаётся флаг завершения.


Контроллер статуса опрашивает этот менеджер: сколько запросов выполнено, сколько времени прошло и т.д. (Такие данные дублируют метрики, но можно и напрямую хранить счётчики в менеджере).


Остановка теста: должна быть аккуратно реализована – например, через volatile boolean флаг running = false + у планировщика проверка этого флага между запросами (или прерывание потоков). После остановки все ресурсы (потоки, соединения) освобождаются.


Логирование (Logging) – кросс-компонентный аспект: все важные события пишутся в лог. Используется стандартный логгер (например, SLF4J + Logback).


На info уровне: запуск теста (с параметрами), завершение теста (с итогами: сколько запросов, ошибок, ср. время ответа и т.п.), остановка по команде, существенные изменения (например, начало всплеска, если нужно).


На error уровне: исключения, сбои при отправке запросов, например невозможность резолва DNS, соединение отказано, и т.д. (впрочем, такие вещи можно учитывать и как часть ошибки запроса).


Логи выводятся в консоль (stdout) – в Docker они будут собираться лог-драйвером Docker. По желанию настраивается также вывод в файл (например, logs/app.log внутри контейнера), но это не строго обязательно, можно опираться на консольные логи.


Формат логов: желательно включать временные метки, уровень, сообщение. Например: [2026-01-10 12:00:00,123 INFO] Started load test (profile=burst, target=http://... , duration=60s, baseRps=100, spikeRps=500)...


Docker-окружение: Сервис должен корректно работать в контейнере. Это означает, что никаких привязок к локальной файловой системе (кроме как для конфигов, которые мапятся), порты должны быть настраиваемыми через переменные (например, SERVER_PORT), etc. В Dockerfile потребуется:


От базового образа (например, openjdk:17-jdk-slim) копировать jar,


Определить ENTRYPOINT, который запускает приложение (java -jar ...),


Экспонировать порт (например 8080).



Для поддержки обоих вариантов, можно сделать так: если при запуске контейнера указан env CONFIG_FILE, то сразу запуск теста и выход, иначе – запуск веб-сервера. Но это усложняет. Возможно проще собрать два образа или запускать с разными аргументами. В рамках ТЗ можно описать один способ (REST-сервис), а CLI использовать вне Docker (или в Docker, но как показано выше, одноразово).


Модуль расширяемости (hook-ы): архитектура должна позволять в будущем добавлять новые типы профилей (например, Ramp-up, Random Walk и т.д.), новые опции (аутентификация, прокси) без значительных переделок. Для этого профили лучше сделать интерфейсом/абстрактным классом, а не жёстко зашитыми if-ами. Аналогично с HTTP-клиентом: использовать абстракцию (интерфейс RequestExecutor), чтобы его можно было заменить (например, на другой HTTP-бэкенд).


Диаграмма компонентной архитектуры может выглядеть следующим образом (логическая схема):
Input: JSON Config (через файл или REST) →


Config Parser (создаёт TestConfig объект) →


Profile Factory (по типу профиля из конфигурации создаёт инстанс ProfileStrategy) →


Test Manager (запускает тест: создает Scheduler и HTTP Client, инициирует Worker Threads) →


Scheduler (в цикле генерирует по ProfileStrategy либо напрямую RPS и выдаёт задания HTTP Client'у) →


HTTP Client (отправляет запросы, возвращает результат) →


Metrics (фиксирует результат, считает RPS, ошибки, время) + Logger (пишет события) →


... до остановки по времени или команде.


Prometheus Endpoint (параллельно доступен для опроса, предоставляется Micrometer).


(Изображение, если бы было, показало бы как конфиг идёт в профиль, профиль в планировщик, тот управляет worker-ами, они шлют запросы и отчитываются в метрики.)
6. Масштабируемость и производительность
   Сервис A изначально проектируется так, чтобы его можно было масштабировать и адаптировать под разную нагрузку:
   Горизонтальное масштабирование: Для увеличения общей генерируемой нагрузки можно запускать несколько экземпляров сервиса параллельно (например, на разных узлах или контейнерах). Они могут работать независимо, каждый на свой целевой URL или на один и тот же (если нужно скоординированно повысить RPS). Поскольку состояние теста полностью локально в пределах одного экземпляра и внешний мир видит их как отдельных клиентов, проблем с согласованностью нет. Если необходимо, координация (например, одновременный старт) может осуществляться внешним оркестратором. В итоге суммарная нагрузка складывается. Примечание: метрики Prometheus с разных инстансов будут раздельными, их можно агрегировать с помощью promQL при анализе (например, sum по instance).


Вертикальная масштабируемость: На уровне одного экземпляра сервис должен эффективно использовать доступные ресурсы:


Использование асинхронного I/O или достаточного числа потоков позволяет генерировать тысячи RPS с одной машины. Следует убедиться, что нет блокирующих операций, которые лимиитируют throughput (например, запись логов очень частая – можно делать не чаще чем X в секунду или писать агрегировано).


В Docker контейнере можно настроить лимиты CPU/Memory; сервис должен корректно работать и под ограничениями (вплоть до того, что если не хватает CPU на заданный RPS, реальный RPS будет ниже, но сервис остаётся стабильным).


Тестирование производительности генератора: Так как цель – нагрузить систему, сам генератор должен быть лёгким. Желательно провести профилирование или тесты генерации N запросов/с (к некоему локальному быстрым endpoint) чтобы удостовериться, что он способен достичь нужной интенсивности. Если возникнут узкие места (например, у RestTemplate – блокировка на сокетах, или у WebClient – слишком много контекста), можно тюнинговать (увеличить размеры пулов, оптимизировать JSON parse, отключить лишние Spring Boot компоненты, например, не грузить веб-сервер если не нужен).


Ограничения: Один экземпляр, конечно, не бесконечно масштабируется – например, на 1 vCPU генерировать более 1000-2000 RPS может быть уже проблематично (в зависимости от простоты целевого URL). Поэтому на очень высокие нагрузки (десятки тысяч RPS) точно потребуется несколько экземпляров и/или распределение по машинам.


Масштабируемость управления: Если предполагается одновременный запуск нескольких тестов, архитектура может быть расширена для поддержания списка активных тестов. Однако, по ТЗ параллельно один экземпляр запускает один тест. Для большего – использовать несколько экземпляров (или доработать под мульти-тест, но это сложно).


7. Логирование
   Как упоминалось, сервис ведёт протокол работы в логах. Ключевые аспекты логирования:
   Техническая реализация: Использовать встроенные возможности Spring Boot (логгер Logback по умолчанию) или другую библиотеку, но настроить её через application.properties (например, уровень логирования и шаблон вывода). По умолчанию Spring Boot пишет в консоль. Можно указать logging.file.name=app.log чтобы дублировать лог в файл.


Формат сообщений: Включает отметку времени, уровень, источник (класс) и текст. Например:

2026-01-10 15:45:12.345  INFO 1 --- [main] LoadGeneratorApp : Starting load test {profile=constant, rps=100, duration=60s, target=http://example.com}
2026-01-10 15:45:13.789  WARN 1 --- [pool-1-thread-3] HttpClient : Request failed (Connection refused) - will count as error.
2026-01-10 15:46:12.001  INFO 1 --- [main] LoadGeneratorApp : Test completed: 6000 requests sent, 0 errors, avg latency 50ms, p95 80ms.


Уровни логирования:


INFO – основная информация о ходе теста: старт, параметры, окончание, основные статистики.


DEBUG – более подробная отладочная информация (по умолчанию выключено). Например, можно на debug выводить каждые N секунд промежуточный прогресс, или подробности планирования (но это не стоит делать на большом RPS, чтобы не замедлять).


ERROR – неожиданные ситуации: ошибки парсинга конфига, необработанные исключения в потоках генерации, и т.д.


WARN – предупреждения, например если слишком медленный отклик или пропуски запросов.


Консоль vs файл: В Docker среде обычно достаточно консоли, т.к. сбор логов централизован. Но можно настроить опциональный вывод в файл (например, через volume). Если реализуется – файл должен расти ограниченно (можно настроить rolling policy, например, раз в 10MB новый).


Примеры лог-сообщений:


При запуске: "Starting load test with profile=burst (baseRps=100, spikeRps=500) for 120s targeting http://example.com..."


При достижении всплеска (если нужно): "Burst peak started at t=30s (target RPS=500)"


При ошибке запроса: "Request error: HTTP 500 Internal Server Error (counting as failure)".


При остановке: "Load test stopped by user after 45s. Sent 4500 requests."


Структурированность: Логировать в JSON-формате для удобства разбора, но текстовый читабельный формат тоже подходит.


