# Порядок запуска сервисов и тест‑кейсы

Этот файл описывает рекомендуемую последовательность запуска сервисов
платформы и компактный набор тест‑кейсов. Замените хосты, порты и переменные
окружения под вашу среду.

## Порядок запуска
1. Redis (нужен сервису C). Пример: `docker run -p 6379:6379 redis:7`.
2. Сервис B (целевой). Проверьте, что health‑эндпоинт отвечает 200.
3. Сервис C (прокси/лимитер). Задайте `REDIS_URL`, `TARGET_URL` и при
   адаптивном режиме `AI_SERVICE_URL`.
4. ИИ‑модуль. Запускайте до включения адаптивного режима в C.
   Пример: `uvicorn main:app --host 0.0.0.0 --port 8083`.
   Docker‑запуск:
   `docker build -t ai-module .`
   `docker run --rm -p 8083:8083 ai-module`
5. Prometheus (опционально). Настройте scrape‑цели для A/B/C и ИИ‑модуля.
6. Сервис A (генератор нагрузки). Укажите `limiterUrl` на сервис C.

## Тест‑кейсы

### ИИ‑модуль
TC-AI-01 Health endpoint: GET `/health` возвращает `{"status":"UP"}`.
TC-AI-02 Метрики: GET `/metrics` возвращает метрики `ai_*`.
TC-AI-03 Валидный запрос: POST `/v1/limit-config` с корректным телом;
          ожидается 200 и конфигурация с `algorithm` и нужными полями.
TC-AI-04 Fallback при валидации: отправить некорректный `currentConfig`;
          ожидается 200 с последней валидной конфигурацией или безопасным
          дефолтом.
TC-AI-05 Fallback прогноза: запуск без Prophet; ответ все равно формируется.

### Сервис C (прокси/лимитер)
TC-C-01 Config API: установить лимиты (fixed/sliding/token) и прочитать их.
TC-C-02 Ниже лимита: запросы проходят в B (2xx).
TC-C-03 Выше лимита: запросы отклоняются с 429.
TC-C-04 Fail‑open Redis: остановить Redis; C пропускает трафик и логирует
          предупреждения.
TC-C-05 Интеграция с ИИ: при работающем ИИ C применяет рекомендации по расписанию.
TC-C-06 ИИ недоступен: остановить ИИ; C продолжает с последней валидной конфигурацией.

### Сервис B (целевой)
TC-B-01 Health endpoint отвечает OK.
TC-B-02 Отвечает на проксируемые GET со стабильной задержкой при нормальной нагрузке.

### Сервис A (генератор нагрузки)
TC-A-01 Start/stop: POST `/test/start` и `/test/stop` управляют нагрузкой.
TC-A-02 Constant профиль: наблюдаемый RPS близок к целевому.
TC-A-03 Burst профиль: пики достигают `spikeRps`, база — `baseRps`.
TC-A-04 Sinusoidal профиль: RPS колеблется между `minRps` и `maxRps`.
TC-A-05 Poisson профиль: интервалы между запросами распределены экспоненциально.
TC-A-06 DDoS профиль: хаотичные пики до `maxRps` с паузами.

### Prometheus / мониторинг
TC-M-01 Скрейп A/B/C `/actuator/prometheus` и ИИ `/metrics`.
TC-M-02 Проверить счетчики и гистограммы задержек для allow/deny.

## Быстрые проверки
- Используйте `test_main.http` для ручной проверки ИИ‑модуля.
- Проверьте C и B через curl на 200 vs 429.

## Мониторинг через Prometheus и Grafana
В репозитории добавлены `prometheus.yml` и `docker-compose.yml` для быстрого
старта Prometheus + Grafana.

1. Проверьте цели в `prometheus.yml` и замените `ai-module`, `service-a`,
   `service-b`, `service-c` на доступные адреса. Если сервисы запущены
   на хосте, используйте `host.docker.internal:PORT`.
2. Запустите мониторинг: `docker compose up -d`.
3. Откройте Grafana: `http://localhost:3000` (логин/пароль по умолчанию
   обычно `admin`/`admin`).
4. Добавьте Prometheus как источник данных (`http://prometheus:9090`) и
   постройте графики по метрикам `ai_*` и `ratelimiter_*`.

## Примечание по логам (Docker‑запуск)
При запуске ИИ‑модуля через Docker в логах могут появляться записи вида:
`GET /metrics 200 OK` и `GET /favicon.ico 404 Not Found`. Это нормально:
браузер запрашивает favicon, которого у сервиса нет.
